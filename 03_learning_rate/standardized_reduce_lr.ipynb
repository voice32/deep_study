{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations\n",
    "\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "units = 64\n",
    "experiments = 5\n",
    "start = 0\n",
    "\n",
    "activations = ['selu', 'sigmoid']\n",
    "optimizers = ['Adamax', 'sgd']\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        'factor': 0.2, \n",
    "        'patience': 10,  \n",
    "        'cooldown': 5\n",
    "    },\n",
    "    {\n",
    "        'factor': 0.35, \n",
    "        'patience': 10, \n",
    "        'cooldown': 5\n",
    "    },\n",
    "    {\n",
    "        'factor': 0.5, \n",
    "        'patience': 10, \n",
    "        'cooldown': 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "def standardize_sample_wise(dataset):\n",
    "    standardized = []\n",
    "    for s in dataset:\n",
    "        mean, std = s.mean(), s.std()\n",
    "        s = (s - mean) / std\n",
    "        standardized.append(s)\n",
    "    return np.array(standardized)\n",
    "\n",
    "x_train = standardize_sample_wise(x_train)\n",
    "x_test = standardize_sample_wise(x_test)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation selu with optimizer Adamax with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "Test accuracy: 0.9815\n",
      "Remaining time: 0 days 10 hours 35 minutes 49 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 4.0960004832335533e-11.\n",
      "Test accuracy: 0.9814\n",
      "Remaining time: 0 days 10 hours 18 minutes 16 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 4.0960004832335533e-11.\n",
      "Test accuracy: 0.9813\n",
      "Remaining time: 0 days 10 hours 14 minutes 52 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 4.0960004832335533e-11.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 8.192001244022862e-12.\n",
      "Test accuracy: 0.9816\n",
      "Remaining time: 0 days 10 hours 24 minutes 31 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "Test accuracy: 0.9804\n",
      "Remaining time: 0 days 10 hours 30 minutes 32 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Test accuracy: 0.98\n",
      "Remaining time: 0 days 10 hours 22 minutes 01 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Test accuracy: 0.978\n",
      "Remaining time: 0 days 10 hours 11 minutes 57 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Test accuracy: 0.9774\n",
      "Remaining time: 0 days 10 hours 01 minutes 27 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Test accuracy: 0.9793\n",
      "Remaining time: 0 days 9 hours 51 minutes 14 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Test accuracy: 0.9779\n",
      "Remaining time: 0 days 9 hours 40 minutes 10 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "Test accuracy: 0.9744\n",
      "Remaining time: 0 days 9 hours 30 minutes 29 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 4.0960004832335533e-11.\n",
      "Test accuracy: 0.9737\n",
      "Remaining time: 0 days 9 hours 19 minutes 38 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 2.048000213861201e-10.\n",
      "Test accuracy: 0.9731\n",
      "Remaining time: 0 days 9 hours 09 minutes 29 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.9741\n",
      "Remaining time: 0 days 8 hours 57 minutes 55 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "Test accuracy: 0.9748\n",
      "Remaining time: 0 days 8 hours 46 minutes 39 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Test accuracy: 0.9663\n",
      "Remaining time: 0 days 8 hours 33 minutes 35 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Test accuracy: 0.9667\n",
      "Remaining time: 0 days 8 hours 20 minutes 22 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9676\n",
      "Remaining time: 0 days 8 hours 07 minutes 27 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Test accuracy: 0.9653\n",
      "Remaining time: 0 days 7 hours 54 minutes 26 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Test accuracy: 0.9664\n",
      "Remaining time: 0 days 7 hours 41 minutes 35 seconds\n",
      "Training for activation selu with optimizer Adamax with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "Test accuracy: 0.9804\n",
      "Remaining time: 0 days 7 hours 31 minutes 03 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9813\n",
      "Remaining time: 0 days 7 hours 20 minutes 09 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.9309830179281562e-08.\n",
      "Test accuracy: 0.9817\n",
      "Remaining time: 0 days 7 hours 07 minutes 20 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.9309830179281562e-08.\n",
      "Test accuracy: 0.9821\n",
      "Remaining time: 0 days 6 hours 52 minutes 29 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "Test accuracy: 0.9811\n",
      "Remaining time: 0 days 6 hours 38 minutes 03 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.8382657435722647e-05.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 6.433930229832185e-06.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 2.25187554860895e-06.\n",
      "Test accuracy: 0.9788\n",
      "Remaining time: 0 days 6 hours 23 minutes 22 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.8382657435722647e-05.\n",
      "Test accuracy: 0.9797\n",
      "Remaining time: 0 days 6 hours 09 minutes 05 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.8382657435722647e-05.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 6.433930229832185e-06.\n",
      "Test accuracy: 0.9783\n",
      "Remaining time: 0 days 5 hours 55 minutes 10 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.8382657435722647e-05.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 6.433930229832185e-06.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 2.25187554860895e-06.\n",
      "Test accuracy: 0.9785\n",
      "Remaining time: 0 days 5 hours 41 minutes 35 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.8382657435722647e-05.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 6.433930229832185e-06.\n",
      "Test accuracy: 0.9799\n",
      "Remaining time: 0 days 5 hours 28 minutes 34 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "Test accuracy: 0.9752\n",
      "Remaining time: 0 days 5 hours 15 minutes 47 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "Test accuracy: 0.9744\n",
      "Remaining time: 0 days 5 hours 03 minutes 10 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "Test accuracy: 0.9747\n",
      "Remaining time: 0 days 4 hours 50 minutes 44 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "Test accuracy: 0.9756\n",
      "Remaining time: 0 days 4 hours 38 minutes 33 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 5.517094194829042e-08.\n",
      "Test accuracy: 0.9742\n",
      "Remaining time: 0 days 4 hours 26 minutes 31 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "Test accuracy: 0.9675\n",
      "Remaining time: 0 days 4 hours 14 minutes 20 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "Test accuracy: 0.9692\n",
      "Remaining time: 0 days 4 hours 02 minutes 19 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "Test accuracy: 0.9684\n",
      "Remaining time: 0 days 3 hours 50 minutes 27 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9699\n",
      "Remaining time: 0 days 3 hours 38 minutes 44 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9688\n",
      "Remaining time: 0 days 3 hours 27 minutes 14 seconds\n",
      "Training for activation selu with optimizer Adamax with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9812\n",
      "Remaining time: 0 days 3 hours 16 minutes 19 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Test accuracy: 0.9814\n",
      "Remaining time: 0 days 3 hours 05 minutes 29 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Test accuracy: 0.9818\n",
      "Remaining time: 0 days 2 hours 54 minutes 44 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Test accuracy: 0.9825\n",
      "Remaining time: 0 days 2 hours 44 minutes 04 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Test accuracy: 0.9815\n",
      "Remaining time: 0 days 2 hours 33 minutes 26 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Test accuracy: 0.9791\n",
      "Remaining time: 0 days 2 hours 22 minutes 43 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Test accuracy: 0.9786\n",
      "Remaining time: 0 days 2 hours 12 minutes 09 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Test accuracy: 0.9785\n",
      "Remaining time: 0 days 2 hours 01 minutes 40 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Test accuracy: 0.9804\n",
      "Remaining time: 0 days 1 hours 51 minutes 16 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Test accuracy: 0.9796\n",
      "Remaining time: 0 days 1 hours 40 minutes 53 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9763\n",
      "Remaining time: 0 days 1 hours 30 minutes 35 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Test accuracy: 0.9742\n",
      "Remaining time: 0 days 1 hours 20 minutes 19 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9747\n",
      "Remaining time: 0 days 1 hours 10 minutes 06 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9756\n",
      "Remaining time: 0 days 0 hours 59 minutes 58 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Test accuracy: 0.9758\n",
      "Remaining time: 0 days 0 hours 49 minutes 52 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9671\n",
      "Remaining time: 0 days 0 hours 39 minutes 45 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Test accuracy: 0.969\n",
      "Remaining time: 0 days 0 hours 29 minutes 44 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9676\n",
      "Remaining time: 0 days 0 hours 19 minutes 45 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9673\n",
      "Remaining time: 0 days 0 hours 09 minutes 50 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Test accuracy: 0.9656\n",
      "Remaining time: 0 days 0 hours 00 minutes 00 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "counter = 0\n",
    "total_items = len(activations) * len(optimizers) * experiments * len(configs)\n",
    "\n",
    "for cfg in configs:\n",
    "    for act in activations:\n",
    "        for opt in optimizers:\n",
    "            print(\"Training for activation \" + act + \" with optimizer \" + opt + ' with config ' + str(cfg))\n",
    "            for i in range(experiments):\n",
    "                K.clear_session()\n",
    "                K.reset_uids()\n",
    "\n",
    "                act_dict = {\n",
    "                  'sigmoid': Activation(keras.activations.sigmoid),\n",
    "                  'tanh': Activation(keras.activations.tanh),\n",
    "                  'relu': Activation(keras.activations.relu),\n",
    "                  'linear': Activation(keras.activations.linear),\n",
    "                  'elu': Activation(keras.activations.elu),\n",
    "                  'softplus': Activation(keras.activations.softplus),\n",
    "                  'softsign': Activation(keras.activations.softsign),\n",
    "                  'hard_sigmoid': Activation(keras.activations.hard_sigmoid),\n",
    "                  'LeakyReLU': keras.layers.advanced_activations.LeakyReLU(),\n",
    "                  'PReLU': keras.layers.advanced_activations.PReLU(),\n",
    "                  'selu': Activation(keras.activations.selu),\n",
    "                  'ThresholdedReLU': keras.layers.advanced_activations.ThresholdedReLU(theta=0.7) # As proposed in the original paper\n",
    "                }\n",
    "\n",
    "                opt_dict = {\n",
    "                  'rmsp': keras.optimizers.rmsprop(lr=0.001),\n",
    "                  'adam': keras.optimizers.Adam(),\n",
    "                  'sgd': keras.optimizers.SGD(),\n",
    "                  'Adagrad': keras.optimizers.Adagrad(),\n",
    "                  'Adadelta': keras.optimizers.Adadelta(),\n",
    "                  'Adamax': keras.optimizers.Adamax(),\n",
    "                  'Nadam': keras.optimizers.Nadam()\n",
    "                }\n",
    "\n",
    "            \n",
    "                model_name = 'std_lr_' + str(cfg['factor']) + '_' + act + \"_\" + opt + '_' + str(i + start)\n",
    "                inputs = Input(shape=(784,))\n",
    "                x = Dense(units, name = 'dense_1')(inputs)\n",
    "                x = act_dict[act](x)\n",
    "                x = Dropout(0.2)(x)\n",
    "                x = Dense(units, name = 'dense_2')(x)\n",
    "                x = act_dict[act](x)\n",
    "                x = Dropout(0.2)(x)\n",
    "                predictions = Dense(num_classes, activation='softmax', name = 'dense_output')(x)\n",
    "                model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                                  optimizer=opt_dict[opt],\n",
    "                                  metrics=['accuracy'])\n",
    "                print('-'*30)\n",
    "                print('Experiment', i)\n",
    "\n",
    "                csv_logger = CSVLogger('./training_logs/%s_%d.csv' % (model_name, units), append=False)\n",
    "                reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=cfg['factor'], patience=cfg['patience'], verbose=1, mode='auto', epsilon=0.0001, cooldown=cfg['cooldown'], min_lr=0)\n",
    "                history = model.fit(x_train, y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=epochs,\n",
    "                                    verbose=0,\n",
    "                                    validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "                score = model.evaluate(x_test, y_test, verbose=0)\n",
    "                print('Test accuracy:', score[1])\n",
    "                \n",
    "                t = time.time()\n",
    "                time_diff = t - start_time\n",
    "                counter +=1\n",
    "                rem_items = total_items - counter\n",
    "                total_time = round((total_items / counter) * time_diff)\n",
    "                rem_time = round(total_time - time_diff)\n",
    "                m, s = divmod(rem_time, 60)\n",
    "                h, m = divmod(m, 60)\n",
    "                d, h = divmod(h, 24)\n",
    "                print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
