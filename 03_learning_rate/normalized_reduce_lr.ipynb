{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import CSVLogger, ReduceLROnPlateau\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "units = 64\n",
    "experiments = 5\n",
    "start = 0\n",
    "\n",
    "activations = ['selu', 'sigmoid']\n",
    "optimizers = ['Adamax', 'sgd']\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        'factor': 0.2, \n",
    "        'patience': 10,  \n",
    "        'cooldown': 5\n",
    "    },\n",
    "    {\n",
    "        'factor': 0.35, \n",
    "        'patience': 10, \n",
    "        'cooldown': 5\n",
    "    },\n",
    "    {\n",
    "        'factor': 0.5, \n",
    "        'patience': 10, \n",
    "        'cooldown': 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation selu with optimizer Adamax with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.9807\n",
      "Remaining time: 0 days 8 hours 24 minutes 37 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "Test accuracy: 0.9798\n",
      "Remaining time: 0 days 8 hours 03 minutes 31 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.978\n",
      "Remaining time: 0 days 7 hours 47 minutes 08 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.9797\n",
      "Remaining time: 0 days 7 hours 38 minutes 10 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.9791\n",
      "Remaining time: 0 days 7 hours 36 minutes 02 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Test accuracy: 0.9701\n",
      "Remaining time: 0 days 7 hours 33 minutes 42 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Test accuracy: 0.9713\n",
      "Remaining time: 0 days 7 hours 28 minutes 46 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Test accuracy: 0.9711\n",
      "Remaining time: 0 days 7 hours 21 minutes 33 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Test accuracy: 0.9717\n",
      "Remaining time: 0 days 7 hours 18 minutes 14 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Test accuracy: 0.9693\n",
      "Remaining time: 0 days 7 hours 13 minutes 40 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.02400008472614e-09.\n",
      "Test accuracy: 0.9766\n",
      "Remaining time: 0 days 7 hours 07 minutes 26 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "Test accuracy: 0.9757\n",
      "Remaining time: 0 days 7 hours 01 minutes 00 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 5.1200004236306995e-09.\n",
      "Test accuracy: 0.9766\n",
      "Remaining time: 0 days 6 hours 55 minutes 05 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "Test accuracy: 0.9743\n",
      "Remaining time: 0 days 6 hours 48 minutes 30 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "Test accuracy: 0.9767\n",
      "Remaining time: 0 days 6 hours 40 minutes 50 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.2, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9528\n",
      "Remaining time: 0 days 6 hours 31 minutes 04 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9518\n",
      "Remaining time: 0 days 6 hours 22 minutes 20 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9516\n",
      "Remaining time: 0 days 6 hours 14 minutes 41 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9535\n",
      "Remaining time: 0 days 6 hours 06 minutes 54 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9512\n",
      "Remaining time: 0 days 5 hours 59 minutes 05 seconds\n",
      "Training for activation selu with optimizer Adamax with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "Test accuracy: 0.979\n",
      "Remaining time: 0 days 5 hours 54 minutes 56 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "Test accuracy: 0.9789\n",
      "Remaining time: 0 days 5 hours 53 minutes 04 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "Test accuracy: 0.9805\n",
      "Remaining time: 0 days 5 hours 52 minutes 54 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "Test accuracy: 0.9802\n",
      "Remaining time: 0 days 5 hours 57 minutes 31 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "Test accuracy: 0.9792\n",
      "Remaining time: 0 days 5 hours 59 minutes 31 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "Test accuracy: 0.9713\n",
      "Remaining time: 0 days 5 hours 57 minutes 59 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 5.252187766018323e-05.\n",
      "Test accuracy: 0.9691\n",
      "Remaining time: 0 days 5 hours 54 minutes 48 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "Test accuracy: 0.97\n",
      "Remaining time: 0 days 5 hours 51 minutes 26 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.0034999999217689036.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0012249999563209713.\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0004287500050850212.\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 0.00015006250177975743.\n",
      "Test accuracy: 0.9715\n",
      "Remaining time: 0 days 5 hours 46 minutes 57 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9742\n",
      "Remaining time: 0 days 5 hours 41 minutes 48 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "Test accuracy: 0.9774\n",
      "Remaining time: 0 days 5 hours 36 minutes 54 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "Test accuracy: 0.9765\n",
      "Remaining time: 0 days 5 hours 31 minutes 22 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1.5763126413048666e-07.\n",
      "Test accuracy: 0.9754\n",
      "Remaining time: 0 days 5 hours 25 minutes 22 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "Test accuracy: 0.9786\n",
      "Remaining time: 0 days 5 hours 18 minutes 32 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 8.575000101700424e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 3.001249933731742e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1.0504374768061097e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 3.676531105156755e-06.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.2867859027210216e-06.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 4.503750460571609e-07.\n",
      "Test accuracy: 0.9757\n",
      "Remaining time: 0 days 5 hours 11 minutes 30 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.35, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9502\n",
      "Remaining time: 0 days 5 hours 01 minutes 06 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9522\n",
      "Remaining time: 0 days 4 hours 49 minutes 00 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9528\n",
      "Remaining time: 0 days 4 hours 36 minutes 44 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9535\n",
      "Remaining time: 0 days 4 hours 24 minutes 25 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9508\n",
      "Remaining time: 0 days 4 hours 12 minutes 09 seconds\n",
      "Training for activation selu with optimizer Adamax with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9782\n",
      "Remaining time: 0 days 4 hours 00 minutes 38 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9784\n",
      "Remaining time: 0 days 3 hours 48 minutes 53 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Test accuracy: 0.9791\n",
      "Remaining time: 0 days 3 hours 37 minutes 01 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9807\n",
      "Remaining time: 0 days 3 hours 25 minutes 04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Test accuracy: 0.9811\n",
      "Remaining time: 0 days 3 hours 12 minutes 57 seconds\n",
      "Training for activation selu with optimizer sgd with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Test accuracy: 0.9718\n",
      "Remaining time: 0 days 3 hours 00 minutes 33 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Test accuracy: 0.9708\n",
      "Remaining time: 0 days 2 hours 48 minutes 06 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Test accuracy: 0.9715\n",
      "Remaining time: 0 days 2 hours 35 minutes 40 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Test accuracy: 0.9716\n",
      "Remaining time: 0 days 2 hours 23 minutes 10 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Test accuracy: 0.9708\n",
      "Remaining time: 0 days 2 hours 10 minutes 32 seconds\n",
      "Training for activation sigmoid with optimizer Adamax with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Test accuracy: 0.9777\n",
      "Remaining time: 0 days 1 hours 57 minutes 51 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Test accuracy: 0.976\n",
      "Remaining time: 0 days 1 hours 45 minutes 09 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Test accuracy: 0.9752\n",
      "Remaining time: 0 days 1 hours 32 minutes 23 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Test accuracy: 0.9757\n",
      "Remaining time: 0 days 1 hours 19 minutes 32 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Test accuracy: 0.9776\n",
      "Remaining time: 0 days 1 hours 06 minutes 34 seconds\n",
      "Training for activation sigmoid with optimizer sgd with config {'factor': 0.5, 'patience': 10, 'cooldown': 5}\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9541\n",
      "Remaining time: 0 days 0 hours 53 minutes 24 seconds\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9528\n",
      "Remaining time: 0 days 0 hours 40 minutes 10 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9547\n",
      "Remaining time: 0 days 0 hours 26 minutes 49 seconds\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9521\n",
      "Remaining time: 0 days 0 hours 13 minutes 23 seconds\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9532\n",
      "Remaining time: 0 days 0 hours 00 minutes 00 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "counter = 0\n",
    "total_items = len(activations) * len(optimizers) * experiments * len(configs)\n",
    "\n",
    "for cfg in configs:\n",
    "    for act in activations:\n",
    "        for opt in optimizers:\n",
    "            print(\"Training for activation \" + act + \" with optimizer \" + opt + ' with config ' + str(cfg))\n",
    "            for i in range(experiments):\n",
    "            \n",
    "\n",
    "                act_dict = {\n",
    "                  'sigmoid': Activation(keras.activations.sigmoid),\n",
    "                  'tanh': Activation(keras.activations.tanh),\n",
    "                  'relu': Activation(keras.activations.relu),\n",
    "                  'linear': Activation(keras.activations.linear),\n",
    "                  'elu': Activation(keras.activations.elu),\n",
    "                  'softplus': Activation(keras.activations.softplus),\n",
    "                  'softsign': Activation(keras.activations.softsign),\n",
    "                  'hard_sigmoid': Activation(keras.activations.hard_sigmoid),\n",
    "                  'LeakyReLU': keras.layers.advanced_activations.LeakyReLU(),\n",
    "                  'PReLU': keras.layers.advanced_activations.PReLU(),\n",
    "                  'selu': Activation(keras.activations.selu),\n",
    "                  'ThresholdedReLU': keras.layers.advanced_activations.ThresholdedReLU(theta=0.7) # As proposed in the original paper\n",
    "                }\n",
    "\n",
    "                opt_dict = {\n",
    "                  'rmsp': keras.optimizers.rmsprop(lr=0.001),\n",
    "                  'adam': keras.optimizers.Adam(),\n",
    "                  'sgd': keras.optimizers.SGD(),\n",
    "                  'Adagrad': keras.optimizers.Adagrad(),\n",
    "                  'Adadelta': keras.optimizers.Adadelta(),\n",
    "                  'Adamax': keras.optimizers.Adamax(),\n",
    "                  'Nadam': keras.optimizers.Nadam()\n",
    "                }\n",
    "\n",
    "            \n",
    "                model_name = 'normd_lr_' + str(cfg['factor']) + '_' + act + \"_\" + opt + '_' + str(i + start)\n",
    "                inputs = Input(shape=(784,))\n",
    "                x = Dense(units, name = 'dense_1')(inputs)\n",
    "                x = act_dict[act](x)\n",
    "                x = Dropout(0.2)(x)\n",
    "                x = Dense(units, name = 'dense_2')(x)\n",
    "                x = act_dict[act](x)\n",
    "                x = Dropout(0.2)(x)\n",
    "                predictions = Dense(num_classes, activation='softmax', name = 'dense_output')(x)\n",
    "                model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                                  optimizer=opt_dict[opt],\n",
    "                                  metrics=['accuracy'])\n",
    "                print('-'*30)\n",
    "                print('Experiment', i)\n",
    "\n",
    "                csv_logger = CSVLogger('./training_logs/%s_%d.csv' % (model_name, units), append=False)\n",
    "                reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=cfg['factor'], patience=cfg['patience'], verbose=1, mode='auto', epsilon=0.0001, cooldown=cfg['cooldown'], min_lr=0)\n",
    "                history = model.fit(x_train, y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=epochs,\n",
    "                                    verbose=0,\n",
    "                                    validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "                score = model.evaluate(x_test, y_test, verbose=0)\n",
    "                print('Test accuracy:', score[1])\n",
    "                \n",
    "                t = time.time()\n",
    "                time_diff = t - start_time\n",
    "                counter +=1\n",
    "                rem_items = total_items - counter\n",
    "                total_time = round((total_items / counter) * time_diff)\n",
    "                rem_time = round(total_time - time_diff)\n",
    "                m, s = divmod(rem_time, 60)\n",
    "                h, m = divmod(m, 60)\n",
    "                d, h = divmod(h, 24)\n",
    "                print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
