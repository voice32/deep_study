{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import CSVLogger, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "units = 64\n",
    "experiments = 5\n",
    "start = 0\n",
    "activations = ['selu', 'sigmoid']\n",
    "optimizers = ['Adamax', 'sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9761\n",
      "Remaining time: 0 days 3 hours 51 minutes 00 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9742\n",
      "Remaining time: 0 days 3 hours 42 minutes 37 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9764\n",
      "Remaining time: 0 days 3 hours 30 minutes 25 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.975\n",
      "Remaining time: 0 days 3 hours 16 minutes 59 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.975\n",
      "Remaining time: 0 days 3 hours 04 minutes 52 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9472\n",
      "Remaining time: 0 days 2 hours 51 minutes 00 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9479\n",
      "Remaining time: 0 days 2 hours 37 minutes 55 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9476\n",
      "Remaining time: 0 days 2 hours 25 minutes 02 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9469\n",
      "Remaining time: 0 days 2 hours 12 minutes 22 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9454\n",
      "Remaining time: 0 days 1 hours 59 minutes 58 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9703\n",
      "Remaining time: 0 days 1 hours 47 minutes 51 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9687\n",
      "Remaining time: 0 days 1 hours 35 minutes 49 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9721\n",
      "Remaining time: 0 days 1 hours 23 minutes 43 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9723\n",
      "Remaining time: 0 days 1 hours 11 minutes 35 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9709\n",
      "Remaining time: 0 days 0 hours 59 minutes 33 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9\n",
      "Remaining time: 0 days 0 hours 47 minutes 23 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.8967\n",
      "Remaining time: 0 days 0 hours 35 minutes 21 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.8964\n",
      "Remaining time: 0 days 0 hours 23 minutes 30 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.8978\n",
      "Remaining time: 0 days 0 hours 11 minutes 44 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9031\n",
      "Remaining time: 0 days 0 hours 00 minutes 00 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "counter = 0\n",
    "total_items = len(activations) * experiments * len(optimizers)\n",
    "\n",
    "for act in activations:\n",
    "    for opt in optimizers:\n",
    "\n",
    "        for i in range(experiments):\n",
    "            print(\"Training for activation \" + act + \" with optimizer \" + opt )\n",
    "\n",
    "            K.clear_session()\n",
    "            K.reset_uids()\n",
    "\n",
    "            # Selecting activation function\n",
    "            act_dict = {\n",
    "              'sigmoid': Activation(keras.activations.sigmoid),\n",
    "              'tanh': Activation(keras.activations.tanh),\n",
    "              'relu': Activation(keras.activations.relu),\n",
    "              'linear': Activation(keras.activations.linear),\n",
    "              'elu': Activation(keras.activations.elu),\n",
    "              'softplus': Activation(keras.activations.softplus),\n",
    "              'softsign': Activation(keras.activations.softsign),\n",
    "              'hard_sigmoid': Activation(keras.activations.hard_sigmoid),\n",
    "              'LeakyReLU': keras.layers.advanced_activations.LeakyReLU(),\n",
    "              'PReLU': keras.layers.advanced_activations.PReLU(),\n",
    "              'selu': Activation(keras.activations.selu),\n",
    "              'ThresholdedReLU': keras.layers.advanced_activations.ThresholdedReLU(theta=0.7) # As proposed in the original paper\n",
    "            }\n",
    "\n",
    "            opt_dict = {\n",
    "              'rmsp': keras.optimizers.rmsprop(lr=0.001, decay=0.0001),\n",
    "              'adam': keras.optimizers.Adam(decay=0.0001),\n",
    "              'sgd': keras.optimizers.SGD(decay=0.0001),\n",
    "              'Adagrad': keras.optimizers.Adagrad(decay=0.0001),\n",
    "              'Adadelta': keras.optimizers.Adadelta(decay=0.0001),\n",
    "              'Adamax': keras.optimizers.Adamax(decay=0.0001),\n",
    "              'Nadam': keras.optimizers.Nadam(schedule_decay=0.0001)\n",
    "            }\n",
    "          \n",
    "            model_name = 'normd_decay_0.0001_' + act + \"_\" + opt + '_' + str(i + start) + '_' + str(units)\n",
    "            inputs = Input(shape=(784,))\n",
    "            x = Dense(units, name = 'dense_1')(inputs)\n",
    "            x = act_dict[act](x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(units, name = 'dense_2')(x)\n",
    "            x = act_dict[act](x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            predictions = Dense(num_classes, activation='softmax', name = 'dense_output')(x)\n",
    "            model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer=opt_dict[opt],\n",
    "                              metrics=['accuracy'])\n",
    "            print('-'*30)\n",
    "            print('Experiment', i)\n",
    "            \n",
    "            csv_logger = CSVLogger('./training_logs/%s.csv' % (model_name), append=False)\n",
    "            \n",
    "            history = model.fit(x_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=0,\n",
    "                                validation_data=(x_test, y_test), callbacks=[csv_logger])\n",
    "\n",
    "\n",
    "\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test accuracy:', score[1])\n",
    "            \n",
    "            t = time.time()\n",
    "            time_diff = t - start_time\n",
    "            counter +=1\n",
    "            rem_items = total_items - counter\n",
    "            total_time = round((total_items / counter) * time_diff)\n",
    "            rem_time = round(total_time - time_diff)\n",
    "            m, s = divmod(rem_time, 60)\n",
    "            h, m = divmod(m, 60)\n",
    "            d, h = divmod(h, 24)\n",
    "            print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
