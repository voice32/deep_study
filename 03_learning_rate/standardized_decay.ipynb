{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import CSVLogger, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "units = 64\n",
    "experiments = 5\n",
    "start = 0\n",
    "activations = ['selu', 'sigmoid']\n",
    "optimizers = ['Adamax', 'sgd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "def standardize_sample_wise(dataset):\n",
    "    standardized = []\n",
    "    for s in dataset:\n",
    "        mean, std = s.mean(), s.std()\n",
    "        s = (s - mean) / std\n",
    "        standardized.append(s)\n",
    "    return np.array(standardized)\n",
    "\n",
    "x_train = standardize_sample_wise(x_train)\n",
    "x_test = standardize_sample_wise(x_test)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9796\n",
      "Remaining time: 0 days 2 hours 43 minutes 11 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.981\n",
      "Remaining time: 0 days 2 hours 33 minutes 31 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.982\n",
      "Remaining time: 0 days 2 hours 22 minutes 45 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9807\n",
      "Remaining time: 0 days 2 hours 13 minutes 18 seconds\n",
      "Training for activation selu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9806\n",
      "Remaining time: 0 days 2 hours 05 minutes 48 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9722\n",
      "Remaining time: 0 days 1 hours 56 minutes 44 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.9732\n",
      "Remaining time: 0 days 1 hours 47 minutes 35 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9717\n",
      "Remaining time: 0 days 1 hours 37 minutes 59 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9725\n",
      "Remaining time: 0 days 1 hours 28 minutes 47 seconds\n",
      "Training for activation selu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.974\n",
      "Remaining time: 0 days 1 hours 20 minutes 10 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9734\n",
      "Remaining time: 0 days 1 hours 12 minutes 03 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Test accuracy: 0.974\n",
      "Remaining time: 0 days 1 hours 03 minutes 57 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Test accuracy: 0.9744\n",
      "Remaining time: 0 days 0 hours 55 minutes 59 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 3\n",
      "Test accuracy: 0.9732\n",
      "Remaining time: 0 days 0 hours 47 minutes 58 seconds\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 4\n",
      "Test accuracy: 0.9748\n",
      "Remaining time: 0 days 0 hours 39 minutes 58 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Test accuracy: 0.9369\n",
      "Remaining time: 0 days 0 hours 31 minutes 52 seconds\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "counter = 0\n",
    "total_items = len(activations) * len(optimizers) * experiments\n",
    "\n",
    "for act in activations:\n",
    "    for opt in optimizers:\n",
    "\n",
    "        for i in range(experiments):\n",
    "            print(\"Training for activation \" + act + \" with optimizer \" + opt)\n",
    "\n",
    "            K.clear_session()\n",
    "            K.reset_uids()\n",
    "\n",
    "            # Selecting activation function\n",
    "            act_dict = {\n",
    "              'sigmoid': Activation(keras.activations.sigmoid),\n",
    "              'tanh': Activation(keras.activations.tanh),\n",
    "              'relu': Activation(keras.activations.relu),\n",
    "              'linear': Activation(keras.activations.linear),\n",
    "              'elu': Activation(keras.activations.elu),\n",
    "              'softplus': Activation(keras.activations.softplus),\n",
    "              'softsign': Activation(keras.activations.softsign),\n",
    "              'hard_sigmoid': Activation(keras.activations.hard_sigmoid),\n",
    "              'LeakyReLU': keras.layers.advanced_activations.LeakyReLU(),\n",
    "              'PReLU': keras.layers.advanced_activations.PReLU(),\n",
    "              'selu': Activation(keras.activations.selu),\n",
    "              'ThresholdedReLU': keras.layers.advanced_activations.ThresholdedReLU(theta=0.7) # As proposed in the original paper\n",
    "            }\n",
    "\n",
    "            opt_dict = {\n",
    "              'rmsp': keras.optimizers.rmsprop(lr=0.001, decay=0.0001),\n",
    "              'adam': keras.optimizers.Adam(decay=0.0001),\n",
    "              'sgd': keras.optimizers.SGD(decay=0.0001),\n",
    "              'Adagrad': keras.optimizers.Adagrad(decay=0.0001),\n",
    "              'Adadelta': keras.optimizers.Adadelta(decay=0.0001),\n",
    "              'Adamax': keras.optimizers.Adamax(decay=0.0001),\n",
    "              'Nadam': keras.optimizers.Nadam(schedule_decay=0.0001)\n",
    "            }\n",
    "          \n",
    "            model_name = 'std_decay_0.0001_' + act + \"_\" + opt + '_' + str(i + start) + '_' + str(units)\n",
    "            inputs = Input(shape=(784,))\n",
    "            x = Dense(units, name = 'dense_1')(inputs)\n",
    "            x = act_dict[act](x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(units, name = 'dense_2')(x)\n",
    "            x = act_dict[act](x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            predictions = Dense(num_classes, activation='softmax', name = 'dense_output')(x)\n",
    "            model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer=opt_dict[opt],\n",
    "                              metrics=['accuracy'])\n",
    "            print('-'*30)\n",
    "            print('Experiment', i)\n",
    "            \n",
    "            csv_logger = CSVLogger('./training_logs/%s.csv' % (model_name), append=False)\n",
    "            history = model.fit(x_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=0,\n",
    "                                validation_data=(x_test, y_test), callbacks=[csv_logger])\n",
    "\n",
    "\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test accuracy:', score[1])\n",
    "            \n",
    "            t = time.time()\n",
    "            time_diff = t - start_time\n",
    "            counter +=1\n",
    "            rem_items = total_items - counter\n",
    "            total_time = round((total_items / counter) * time_diff)\n",
    "            rem_time = round(total_time - time_diff)\n",
    "            m, s = divmod(rem_time, 60)\n",
    "            h, m = divmod(m, 60)\n",
    "            d, h = divmod(h, 24)\n",
    "            print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
